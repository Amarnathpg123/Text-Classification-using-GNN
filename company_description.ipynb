{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "company description.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po3o3Qq7Pnpv"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y09oLfROKGWp"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "san2H47rKlLa"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import networkx as nx\r\n",
        "import math\r\n",
        "from collections import OrderedDict\r\n",
        "from itertools import combinations\r\n",
        "from tqdm import tqdm\r\n",
        "import resource\r\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkTcC3H7Kt_P"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW4w7qcmKxcG"
      },
      "source": [
        "df = pd.read_excel('/content/gdrive/MyDrive/GNN Intern/Training_Data.xlsx')\r\n",
        "print(df.shape)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL7TAleDLowS"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifyKzCnXMXo7"
      },
      "source": [
        "df[df[\"Business Description\"].isnull() == True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--mwiHNfMchs"
      },
      "source": [
        "df['Business Description'] = np.where(df[\"Business Description\"].isnull() == True,df[\"Company Name\"],df[\"Business Description\"])\r\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-gljSiwRANl"
      },
      "source": [
        "df.drop_duplicates(keep=False,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7whJYw4oRBvU"
      },
      "source": [
        "df.info()\r\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8a0zxzdRETy"
      },
      "source": [
        "df[\"Business Description\"].str.len().describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeY_FjFqSJch"
      },
      "source": [
        "df[\"Business Description\"].str.len().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xv2_hDWSMrh"
      },
      "source": [
        "df[\"Business Description\"].str.len().plot.box()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_XKcs05SQgC"
      },
      "source": [
        "df.iloc[:,1] = df.iloc[:,1].str.lower()\r\n",
        "df.columns = df.columns.str.strip()\r\n",
        "df.columns = df.columns.str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy_9J5fDSZQx"
      },
      "source": [
        "df.drop('company name',1,inplace=True)\r\n",
        "df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daMqIppuScLX"
      },
      "source": [
        "classes = {typ:i for i,typ in enumerate(df.iloc[:,1].unique())}\r\n",
        "#classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzRi2XPG0NPl"
      },
      "source": [
        "df['industry classification tag'].replace(classes,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJdMudd14JU4"
      },
      "source": [
        "# Graph preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpVYyWNTBek"
      },
      "source": [
        "def nCr(n,r):\r\n",
        "    f = math.factorial\r\n",
        "    return int(f(n)/(f(r)*f(n-r)))\r\n",
        "\r\n",
        "def dummy_function(doc): return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEg2nQMz_s_"
      },
      "source": [
        "df['business description'] = df['business description'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo07aEzn12pL"
      },
      "source": [
        "stopwords = list(set(nltk.corpus.stopwords.words(\"english\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1RXjIU92ai7"
      },
      "source": [
        "def filter_tokens(tokens, stopwords):\r\n",
        "    tks = []\r\n",
        "    for token in tokens:\r\n",
        "        if (token not in stopwords) and (token not in [\".\",\",\",\";\",\"&\",\"'s\", \":\", \"?\", \"!\",\"(\",\")\",\\\r\n",
        "            \"'\",\"`\",\"''\",\"\\\"\",\"â€œ\",\" \",\"'m\",\"'no\",\"***\",\"--\",\"...\",\"[\",\"]\",\"{\",\"}\",\"~\",\"@\",\"#\",\"$\",\"%\",\"^\",\"*\",\"/\",\"<\",\">\",\"+\",\"-\",\"=\"]):\r\n",
        "            tks.append(token)\r\n",
        "    return tks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCk-JeUM2Vu7"
      },
      "source": [
        "df['business description'] = df['business description'].apply(lambda x: filter_tokens(x, stopwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQoUb8TE2zDM"
      },
      "source": [
        "vectorizer = TfidfVectorizer(input=\"content\", max_features=None, tokenizer=dummy_function, preprocessor=dummy_function)\r\n",
        "vectorizer.fit(df['business description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNGn93pA3jZo"
      },
      "source": [
        "vocabulary = vectorizer.get_feature_names()\r\n",
        "vocabulary = np.array(vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Oo1lIe6tX9"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ9H5iY43PHk"
      },
      "source": [
        "## TF-IDF preparation (document-word edge weights)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j5g3pIUI0oF"
      },
      "source": [
        "df_tf_idf = vectorizer.transform(df['business description'])\r\n",
        "df_tf_idf = df_tf_idf.toarray()\r\n",
        "df_tf_idf = pd.DataFrame(df_tf_idf,columns=vocabulary)\r\n",
        "df_tf_idf.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI-dzSuBAFQM"
      },
      "source": [
        "G = nx.Graph()\r\n",
        "\r\n",
        "G.add_nodes_from(df_tf_idf.index)\r\n",
        "G.add_nodes_from(vocabulary)\r\n",
        "\r\n",
        "document_word = [(doc,w,{\"weight\":df_tf_idf.loc[doc,w]}) for doc in tqdm(df_tf_idf.index, total=len(df_tf_idf.index))\\\r\n",
        "                     for w in df_tf_idf.columns]\r\n",
        "\r\n",
        "G.add_edges_from(document_word)\r\n",
        "del df_tf_idf\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZhpDmKS3u2p"
      },
      "source": [
        "##PMI preparation (word-word edge weights)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ThaaUR74GkQ"
      },
      "source": [
        "word2index_n_i = OrderedDict()\r\n",
        "for index,name in enumerate(vocabulary):\r\n",
        "  word2index_n_i[name] = [index,0]\r\n",
        "occurrences = np.zeros((len(vocabulary),len(vocabulary)) ,dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXv6JEhw4pre"
      },
      "source": [
        "no_of_windows = 0\r\n",
        "window = 15\r\n",
        "for l in tqdm(df['business description'], total=len(df['business description'])):\r\n",
        "  for i in range(len(l)-window):\r\n",
        "    no_of_windows += 1\r\n",
        "    d = set(l[i:(i+window)])\r\n",
        "\r\n",
        "    for w in d:\r\n",
        "      word2index_n_i[w][1] += 1\r\n",
        "    for w1,w2 in combinations(d,2):\r\n",
        "      i1 = word2index_n_i[w1][0]\r\n",
        "      i2 = word2index_n_i[w2][0]\r\n",
        "\r\n",
        "      occurrences[i1][i2] += 1\r\n",
        "      occurrences[i2][i1] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjEdZNKc9kjN"
      },
      "source": [
        "p_ij = pd.DataFrame(occurrences, index = vocabulary,columns=vocabulary)/no_of_windows\r\n",
        "del occurrences\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jUOACH1-Cah"
      },
      "source": [
        "for col in p_ij.columns:\r\n",
        "  p_ij[col] = p_ij[col]/word2index_n_i[col][1]/(no_of_windows)\r\n",
        "for row in p_ij.index:\r\n",
        "  p_ij.loc[row,:] = p_ij.loc[row,:]/word2index_n_i[row][1]/(no_of_windows)\r\n",
        "\r\n",
        "del word2index_n_i\r\n",
        "p_ij += 1E-9\r\n",
        "for col in p_ij.columns:\r\n",
        "  p_ij[col] = p_ij[col].apply(lambda x: math.log(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ongg5eW7ARsG"
      },
      "source": [
        "def word_word_edges(p_ij):\r\n",
        "    word_word = []\r\n",
        "    cols = list(p_ij.columns)\r\n",
        "    cols = [str(w) for w in cols]\r\n",
        "    for w1, w2 in tqdm(combinations(cols, 2), total=nCr(len(cols), 2)):\r\n",
        "        if (p_ij.loc[w1,w2] > 0):\r\n",
        "            word_word.append((w1,w2,{\"weight\":p_ij.loc[w1,w2]}))\r\n",
        "    return word_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBWeJw4mAfao"
      },
      "source": [
        "word_word = word_word_edges(p_ij)\r\n",
        "del p_ij\r\n",
        "G.add_edges_from(word_word)\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VJZ_jHjvOlW"
      },
      "source": [
        "# GCN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wATBsL5vS34"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnaCspR4z5Uq"
      },
      "source": [
        "class gcn(nn.Module):\r\n",
        "  def __init__(self,X_size, A_hat, bias=True):\r\n",
        "    super(gcn,self).__init__()\r\n",
        "    self.A_hat = torch.tensor(A_hat, requires_grad=False).float()\r\n",
        "    self.weight = nn.parameter.Parameter(torch.FloatTensor(X_size, hidden_size_1))\r\n",
        "    var = 2./(self.weight.size(1)+self.weight.size(0))\r\n",
        "    self.weight.data.normal_(0,var)\r\n",
        "    self.weight2 = nn.parameter.Parameter(torch.FloatTensor(hidden_size_1, hidden_size_2))\r\n",
        "    var2 = 2./(self.weight2.size(1)+self.weight2.size(0))\r\n",
        "    self.weight2.data.normal_(0,var2)\r\n",
        "\r\n",
        "    if bias:\r\n",
        "      self.bias = nn.parameter.Parameter(torch.FloatTensor(hidden_size_1))\r\n",
        "      self.bias.data.normal_(0,var)\r\n",
        "      self.bias2 = nn.parameter.Parameter(torch.FloatTensor(hidden_size_2))\r\n",
        "      self.bias2.data.normal_(0,var2)\r\n",
        "\r\n",
        "    else:\r\n",
        "      self.register_parameter(\"bias\", None)\r\n",
        "    self.fc1 = nn.Linear(hidden_size_2, num_classes)\r\n",
        "\r\n",
        "  def forward(self,X):\r\n",
        "    X = torch.mm(X, self.weight)\r\n",
        "    if self.bias is not None:\r\n",
        "      X = (X + self.bias)\r\n",
        "    X = F.relu(torch.mm(self.A_hat, X))\r\n",
        "    X = torch.mm(X, self.weight2)\r\n",
        "    if self.bias2 is not None:\r\n",
        "      X = (X + self.bias2)\r\n",
        "    X = F.relu(torch.mm(self.A_hat, X))\r\n",
        "    return self.fc1(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qPs8HkQz_sA"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2rbeeDY0DQ6"
      },
      "source": [
        "A = nx.to_numpy_matrix(G, weight=\"weight\")\r\n",
        "A = A + np.eye(G.number_of_nodes())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz6QKpya0LOq"
      },
      "source": [
        "degrees = []\r\n",
        "for d in G.degree(weight=None):\r\n",
        "  if d == 0:\r\n",
        "    degrees.append(0)\r\n",
        "  else:\r\n",
        "    degrees.append(d[1]**(-0.5))\r\n",
        "degrees = np.diag(degrees)\r\n",
        "X = np.eye(G.number_of_nodes())\r\n",
        "A_hat = degrees@A@degrees"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lRPmN2q0Rqf"
      },
      "source": [
        "#X = X.numpy()\r\n",
        "f = X\r\n",
        "X = torch.from_numpy(X)\r\n",
        "\r\n",
        "test_idxs = []\r\n",
        "\r\n",
        "for b_id in df['industry classification tag'].unique():\r\n",
        "  dum = df_data[df['industry classification tag'] == b_id]\r\n",
        "  if len(dum) >= 4:\r\n",
        "    test_idxs.extend(list(np.random.choice(dum.index, size=round(0.2*len(dum)), replace=False)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIZJ6nBN1CIf"
      },
      "source": [
        "selected = []\r\n",
        "for i in range(len(df_data)):\r\n",
        "  if i not in test_idxs:\r\n",
        "    selected.append(i)\r\n",
        "\r\n",
        "f_selected = f[selected]; f_selected = torch.from_numpy(f_selected).float()\r\n",
        "labels_selected = [l for idx, l in enumerate(df['industry classification tag']) if idx in selected]\r\n",
        "f_not_selected = f[test_idxs]; f_not_selected = torch.from_numpy(f_not_selected).float()\r\n",
        "labels_not_selected = [l for idx, l in enumerate(df['industry classification tag']) if idx not in selected]\r\n",
        "f = torch.from_numpy(f).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0alP0fB1FAF"
      },
      "source": [
        "#arguments\r\n",
        "hidden_size_1 = 330\r\n",
        "hidden_size_2 = 130\r\n",
        "num_classes = 62"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sz_W6ZE1QSx"
      },
      "source": [
        "net = gcn(X.shape[1],A_hat)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-36KTxr1TAg"
      },
      "source": [
        "def get_num_correct(preds,labels):\r\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8l8tQu1V_C"
      },
      "source": [
        "lr = 0.3\r\n",
        "'''\r\n",
        "model_save_name = 'company description.pt'\r\n",
        "path = F\"/content/gdrive/My Drive/GNN Intern/saved_models/{model_save_name}\"\r\n",
        "net.load_state_dict(torch.load(path))\r\n",
        "net.train() '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4_XJYjh1jXp"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr)\r\n",
        "output = net(f)\r\n",
        "loss = criterion(output[selected], torch.tensor(labels_selected).long())\r\n",
        "loss.backward()\r\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "560EHb571liX"
      },
      "source": [
        "n = 1000\r\n",
        "for i in range(n):\r\n",
        "  optimizer.zero_grad()\r\n",
        "  output = net(f)\r\n",
        "  loss = criterion(output[selected], torch.tensor(labels_selected).long())\r\n",
        "  loss.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  t_out = output[test_idxs]\r\n",
        "  print('epoch: ',i,' loss: ',loss.item(),' accuracy: ',get_num_correct(t_out,torch.Tensor(labels_not_selected).long())/len(labels_not_selected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bywB6reg1-LK"
      },
      "source": [
        "model_save_name = 'company description.pt'\r\n",
        "path = F\"/content/gdrive/My Drive/GNN Intern/saved_models/{model_save_name}\"\r\n",
        "torch.save(.state_dict(),path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}